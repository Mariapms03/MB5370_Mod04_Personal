---
title: "Workshop 3 - Module 4- Data Wrangling in R"
author: "Maria Paula Munoz"
output: html_document
date: "2024-05-15"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```


```{r message=FALSE, warning=FALSE}
library(tidyverse)
```

## Making the data tidy 

### 4.4 Tidy data 

Tables as example for tidy tables and non-tidy tables
```{r}
table1
#> # A tibble: 6 × 4
#>   country      year  cases population
#>   <chr>       <int>  <int>      <int>
#> 1 Afghanistan  1999    745   19987071
#> 2 Afghanistan  2000   2666   20595360
#> 3 Brazil       1999  37737  172006362
#> 4 Brazil       2000  80488  174504898
#> 5 China        1999 212258 1272915272
#> 6 China        2000 213766 1280428583
table2
#> # A tibble: 12 × 4
#>   country      year type           count
#>   <chr>       <int> <chr>          <int>
#> 1 Afghanistan  1999 cases            745
#> 2 Afghanistan  1999 population  19987071
#> 3 Afghanistan  2000 cases           2666
#> 4 Afghanistan  2000 population  20595360
#> 5 Brazil       1999 cases          37737
#> 6 Brazil       1999 population 172006362
#> # ... with 6 more rows
table3
#> # A tibble: 6 × 3
#>   country      year rate             
#> * <chr>       <int> <chr>            
#> 1 Afghanistan  1999 745/19987071     
#> 2 Afghanistan  2000 2666/20595360    
#> 3 Brazil       1999 37737/172006362  
#> 4 Brazil       2000 80488/174504898  
#> 5 China        1999 212258/1272915272
#> 6 China        2000 213766/1280428583
```

Then we can see we can use pipes to apply functions to our data and also that we need tidy data for ggplot2.
```{r}
# Compute rate per 10,000
table1 %>% 
  mutate(rate = cases / population * 10000)
#> # A tibble: 6 × 5
#>   country      year  cases population  rate
#>   <chr>       <int>  <int>      <int> <dbl>
#> 1 Afghanistan  1999    745   19987071 0.373
#> 2 Afghanistan  2000   2666   20595360 1.29 
#> 3 Brazil       1999  37737  172006362 2.19 
#> 4 Brazil       2000  80488  174504898 5.61 
#> 5 China        1999 212258 1272915272 1.67 
#> 6 China        2000 213766 1280428583 1.67

# Compute cases per year
table1 %>% 
  count(year, wt = cases)
#> # A tibble: 2 × 2
#>    year      n
#>   <int>  <int>
#> 1  1999 250740
#> 2  2000 296920

# Visualise changes over time
library(ggplot2)
ggplot(table1, aes(year, cases)) + 
  geom_line(aes(group = country), colour = "grey50") + 
  geom_point(aes(colour = country))

```

##### 4.4.1 Exercise

```{r}
#NEED TO ANSWER THIS
```

### 4.5 Pivoting data to make it tidy 

Using `pivot_longer()` example wiht the data: 
The billboard dataset records the billboard rank of songs in the year 2000.
```{r}
#dataset 
billboard
#> # A tibble: 317 × 79
#>   artist       track               date.entered   wk1   wk2   wk3   wk4   wk5
#>   <chr>        <chr>               <date>       <dbl> <dbl> <dbl> <dbl> <dbl>
#> 1 2 Pac        Baby Don't Cry (Ke... 2000-02-26      87    82    72    77    87
#> 2 2Ge+her      The Hardest Part O... 2000-09-02      91    87    92    NA    NA
#> 3 3 Doors Down Kryptonite          2000-04-08      81    70    68    67    66
#> 4 3 Doors Down Loser               2000-10-21      76    76    72    69    67
#> 5 504 Boyz     Wobble Wobble       2000-04-15      57    34    25    17    17
#> 6 98^0         Give Me Just One N... 2000-08-19      51    39    34    26    26
#> # ℹ 311 more rows
#> # ℹ 71 more variables: wk6 <dbl>, wk7 <dbl>, wk8 <dbl>, wk9 <dbl>, ...
```

Now we used `pivot_longer()` to change the data set of billboard into long format and have week as a column and then rank as a column. 
```{r}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank"
  )
```

Our long format data set now has NA's because not all songs were present each week. So the NA’s were forced to exist because of the structure of the dataset not because they are actually unknown. Therefore, we can simply ask `pivot_longer` to remove them by adding the argument `values_drop_na = TRUE` as shown below:

```{r}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE #remove NAs from the dataset
  )
```

#### 4.5.2 Pivoting longer

Creating a dataframe 

```{r}
df <- tribble(
  ~id,  ~bp1, ~bp2,
   "A",  100,  120,
   "B",  140,  115,
   "C",  120,  125
)
```

Making the dataframe longer

```{r}
df |> 
  pivot_longer(
    cols = bp1:bp2,
    names_to = "measurement",
    values_to = "value"
  )
```

#### 4.5.3 Widening datasets
Here we will use the `pivot_wider()` to covert a dataframe into wide format, is less common to use but needed sometiemes as we will see in the next example. 

We’ll use an example from R4DS to explore pivot_wider() looking at the cms_patient_experience dataset from the Centers of Medicare and Medicaid.
```{r}
#dataframe
cms_patient_experience
#> # A tibble: 500 × 5
#>   org_pac_id org_nm                     measure_cd   measure_title   prf_rate
#>   <chr>      <chr>                      <chr>        <chr>              <dbl>
#> 1 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_1  CAHPS for MIPS...       63
#> 2 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_2  CAHPS for MIPS...       87
#> 3 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_3  CAHPS for MIPS...       86
#> 4 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_5  CAHPS for MIPS...       57
#> 5 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_8  CAHPS for MIPS...       85
#> 6 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_12 CAHPS for MIPS...       24
#> # ℹ 494 more rows

```

See the complete set of values

```{r}
cms_patient_experience |> 
  distinct(measure_cd, measure_title)
```

`pivot_wider()` has the opposite interface to `pivot_longer()`: instead of choosing new column names, we need to provide the existing columns that define the values (`values_from`) and the column name (`names_from`):

```{r}
cms_patient_experience |> 
  pivot_wider(
    names_from = measure_cd,
    values_from = prf_rate
  )
```

The above output doesn’t look quite right; we still seem to have multiple rows for each organization. That’s because, we also need to tell `pivot_wider()` which column or columns have values that uniquely identify each row; in this case those are the variables starting with `"org"`:

```{r}
cms_patient_experience |> 
  pivot_wider(
    id_cols = starts_with("org"),
    names_from = measure_cd,
    values_from = prf_rate
  )
```

#### 4.5.4 Pivoting wider

To understand what pivot_wider() does to our data, let’s once again use a simple example. This time we have two patients with id s A and B, and we have three blood pressure (bp) measurements from patient A and two from patient B:

```{r}
df <- tribble(
  ~id, ~measurement, ~value,
  "A",        "bp1",    100,
  "B",        "bp1",    140,
  "B",        "bp2",    115, 
  "A",        "bp2",    120,
  "A",        "bp3",    105
)
```

We’ll take the names from the measurement column using the names_from() argument and the values from the value column using the values_from() argument:

```{r}
df |> 
  pivot_wider(
    names_from = measurement,
    values_from = value
  )
```

To start the pivoting process, pivot_wider() needs to first figure out what will go in the rows and columns. The new column names will be the unique values of measurement.

```{r}
df |> 
  distinct(measurement) |> 
  pull()
```

By default, the rows in the output are determined by all the variables that aren’t going into the new names or values. These are called the id_cols. Here there is only one column, but in general there can be any number.

```{r}
df |> 
  select(-measurement, -value) |> 
  distinct()
```

pivot_wider() then combines these results to generate an empty dataframe:

```{r}
df |> 
  select(-measurement, -value) |> 
  distinct() |> 
  mutate(x = NA, y = NA, z = NA)
```

##### 4.5.5 Exercises

```{r}
#ANS here
```

#### 4.5.6 Separating and uniting data tables

We need to split the rate column up into two variables: 1) cases and 2) population. separate() will take the name of the column we want to split and the names of the columns we want it split into. See the code below:

```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"))
```

Separate columns with specific characters

```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"), sep = "/")
```

Notice the data types in table3 above. Both `case`s and `population` are listed as `character` (`<chr>`) types. This is a default of using `separate()`. However, since the values in those columns are actually numbers, we want to ask `separate()` to convert them to better types using `convert = TRUE`. Now you can see they are listed as integer types(`<int>`)

```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"), convert = TRUE)

```

Separate the last two digits of each year. This makes this data less tidy, but is useful in other cases, as you’ll see in a little bit.

```{r}
table3 %>% 
  separate(year, into = c("century", "year"), sep = 2)
```

`Using unite():
To perform the inverse of separate() we will use unite() to combine multiple columns into a single column. In the example below for table5, we use unite() to rejoin century and year columns. unite() takes a data frame, the name of the new variable and a set of columns to combine using dplyr::select(). 

```{r}
table5 %>% 
  unite(new, century, year, sep = "")
```

### 4.6 Handling missing values

Missing values are very common in datasets. I bet you’ve come across many of them, but how you handle them is a key way to separate you, as a trained marine data scientist, from someone who simply hacks away until it seems ok. Missing values are sometimes populated with NA or sometimes they could be simply missing altogether from the data (i.e. a blank cell, the worst!). 

#### 4.6.1 Explicit missing values
The way data is missing matters a lot when tidying your data, so think of it like this: An NA (explicit absence) indicates the presence of absent data, and a blank cell just indicates the absence of data (implicit absence). One you know for sure is a no data value, the other you have no idea!
Let’s begin by exploring some tools for creating or eliminating explicit values, i.e. cells where you see an NA.

```{r}
treatment <- tribble(
  ~person,           ~treatment, ~response,
  "Derrick Whitmore", 1,         7,
  NA,                 2,         10,
  NA,                 3,         NA,
  "Katherine Burke",  1,         4
)
```

You can fill in these missing values with tidyr::fill(). It works like select(), taking a set of columns:

```{r}
treatment |>
  fill(everything())
```

#### 4.6.2 Fixed values
Sometimes missing values represent some fixed and known value, most commonly 0. You can use dplyr::coalesce() to replace them:

```{r}
x <- c(1, 4, 5, 7, NA)
coalesce(x, 0)
```

And sometimes you’ll encounter the opposite problem where some other concrete value actually represents a missing value. This typically happens when data is generated from an older software that can’t properly represent missing values so it uses something like 99 or -999 in place of the missing value. You can fix this with `dplyr::na_if()`:

```{r}
x <- c(1, 4, 5, 7, -99)
na_if(x, -99)
```

#### 4.6.3 NaN
One special type of missing value worth mentioning is NaN or Not a Number. It typically behaves the same as NA but in some rare cases you may need to distinguish it using is.nan(x):

NaN is most common when you performing a mathematical operation that has an indeterminate result.

```{r}
x <- c(NA, NaN)
x * 10
#> [1]  NA NaN
x == 1
#> [1] NA NA
is.na(x)
#> [1] TRUE TRUE
```

#### 4.6.4 Implicit missing values
So far we’ve talked about missing values that are explicitly missing, i.e. you can see an NA in your data. But missing values can also be implicitly missing, if an entire row of data is simply absent from the data. Let’s illustrate the difference with a simple dataset that records the price of some stock each quarter:

```{r}
stocks <- tibble(
  year  = c(2020, 2020, 2020, 2020, 2021, 2021, 2021),
  qtr   = c(   1,    2,    3,    4,    2,    3,    4),
  price = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)
```

This dataset has two missing observations:
The price in the fourth quarter of 2020 is explicitly missing, because its value is NA.
The price for the first quarter of 2021 is implicitly missing, because it simply does not appear in the dataset.

Sometimes you want to make implicit missings explicit in order to have something physical to work with. In other cases, explicit missings are forced upon you by the structure of the data and you want to get rid of them. Remember how we did this when we used pivot_wider()?

Here’s another example where if we pivot stocks wider to put the quarter in the columns, both missing values become explicit:

```{r}
stocks |>
  pivot_wider(
    names_from = qtr, 
    values_from = price
  )
```

### 4.7 How can I import data into R?

Here we will learn how to import different types of files with our data into R. 
The most common type of file is CSV (comma-separated values)

```r
? read_csv
students <- read_csv("C://data/students.csv")

#To play with read_csv() let’s read it into R directly from the URL provided in the textbook (https://pos.it/r4ds-students-csv)

students <- read_csv("https://pos.it/r4ds-students-csv")
```

You might also notice that the Student ID and Full Name columns are surrounded by backticks. That’s because they contain spaces, breaking R’s usual rules for variable names; they’re non-syntactic names (think back to our intro to programming workshop!). To refer to these variables, you need to surround them with backticks, `:

```r
students |> 
  rename(
    student_id = `Student ID`,
    full_name = `Full Name`
  )
```

### 4.8 Learning relational data


